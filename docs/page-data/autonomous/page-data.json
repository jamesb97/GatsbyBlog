{"componentChunkName":"component---src-templates-blog-post-js","path":"/autonomous/","result":{"data":{"site":{"siteMetadata":{"title":"Tech Blog"}},"markdownRemark":{"id":"419935fe-cf16-549d-b7eb-7f46b4087cf3","excerpt":"Autonomous Vehicles are certain types of vehicles that are capable of performing similar actions compared to humans in operating driverless technology through…","html":"<p>Autonomous Vehicles are certain types of vehicles that are capable of performing similar actions compared to humans in operating driverless technology through the ability to sense it’s nearby surroundings. These vehicles are equipped with multiple sensors, lidar, and radar detection optimization, and scene optimization to name a few. Autonomous vehicles technology involves multiple key components when it comes to the proper interaction of an autonomous vehicle. The technology behind autonomous vehicles integration consists of sensors, connectivity, and software controlled algorithms that power the seamless autonomy. Each component plays a big role in allocating an automated vehicle that is able to successfully be on the road.</p>\n<p>Some examples of Autonomous Vehicles include:</p>\n<ul>\n<li>Tesla Model S</li>\n<li>Cadillac CT6</li>\n<li>Mercedes-Benz S-Class</li>\n<li>BMW X7</li>\n</ul>\n<h4>The Concept</h4>\n<p>Self-driving cars, also referred to as autonomous cars or driverless cars, obtains visual information from a series of cameras and sensors, converts it to grayscale, and applies semantic segmentation using AI technology. This then gets the system to process any ongoing changes being interpreted during the driving simulation.</p>\n<p>The 6 different levels of autonomy:</p>\n<p>Level 0: A human driver has total control over all the operations.</p>\n<p>Level 1: A function is automated.</p>\n<p>Level 2: More than one function becomes automated, whether that is the steering wheel and acceleration.</p>\n<p>Level 3: Conditional Automation, capable of performing some tasks.</p>\n<p>Level 4: High Automation, able to perform most tasks.</p>\n<p>Level 5: Fully autonomous in which the vehicle is capable of self operating.</p>\n<p>“To qualify as fully autonomous, a vehicle must be able to navigate without a human intervention to a predetermined destination over roads that have not been adapted for its use.</p>\n<h4>Details</h4>\n<p>Developers behind the autonomous self-driving technologies imply an ample quantity of data including image recognition systems, machine learning and neural networks in order to successfully design an autonomous self-driving experience. The neural networks are responsible for identifying the interpreted data collection patterns by implying machine learning gathered from the camera’s visual interpretation of it’s surrounding environment. Drive OS, offered by Nvidia, is an operating system designed for accelerated computing that offers multiple input sensors processing real-time AI inference. It is crucial in providing input information for autonomous vehicles. It consists of the sensor abstraction layer(SAL), vehicle I/O support and a deep neural network(DNN) framework.</p>\n<p><b>Challenges/Concerns</b>: In March 2018, Elaine Herzberg died after a self-driving Uber Volvo car failed to recognize the object from its camera sensors as a pedestrian in Arizona.</p>\n<p><b>What should be the next steps?</b> More testing that yields better results in classifying each tertiary object within the camera’s sensor point-of-view. Fewer error prone logs.</p>\n<p><b>Google’s self driving project(Waymo)</b>: Waymo utilizes a mixture of sensors including Lidar and consolidates deep learning algorithms with Google Maps.</p>\n<h4>Lidar Technology</h4>\n<p><b>Concept</b>: Lidar(Light detection and ranging) technology is one of the most popular remote sensing approaches when it comes to calculating an object’s exact distance located on Earth’s surface. Lidar implies a pulsed radar that is used to measure the object’s variable distance by emitting light pulses. These light pulses are capable of generating accurate 3D information from the Earth’s surface and its target object. There are three primary components when it comes to Lidar systems: the scanner, laser, and GPS receiver.</p>\n<p>Examples of Lidar Systems being used in production today include Airborne Lidar, and Terrestrial Lidar.</p>\n<p><b>Fundamental</b>: Shine a laser light onto a terrestrial object, and calculate the amount of time required to return its source.</p>\n<p><b>Formula</b>: Distance of the object = (Speed of Light x Time of Flight) / 2.</p>\n<p><b>Developmental Aspirations</b>: Oceanography, Digital Elevation or Terrain Model, Agriculture &#x26; Archaeology.</p>\n<p>Lidar technologies have been rapidly expanding in production, reaching an all time high for consumer demands since 2016 and beyond. Fully autonomous vehicles are expected to hit the market as early as 2027.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 582px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/b5ca186f76e25e7467db1c9cc56608f9/14007/lidar.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 75.31645569620254%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAMBAgQF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAeDLrM5h4v8A/8QAGhABAAIDAQAAAAAAAAAAAAAAAQARAhASIf/aAAgBAQABBQKlnLKmL6t6/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERIf/aAAgBAwEBPwG6VH//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEQH/2gAIAQIBAT8BiY//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAZEAADAQEBAAAAAAAAAAAAAAAAAREhMWH/2gAIAQEAAT8hTiSXTaSF+DEumevhT//aAAwDAQACAAMAAAAQKw//xAAZEQABBQAAAAAAAAAAAAAAAAAAATFBYaH/2gAIAQMBAT8QVqCzD//EABcRAQADAAAAAAAAAAAAAAAAAAARUWH/2gAIAQIBAT8QhbR//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARIUExYf/aAAgBAQABPxB6tqjIanTX5HJFCXZEVsXTkcWrT5nZTqz/2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"lidar\" title=\"lidar\" src=\"/static/b5ca186f76e25e7467db1c9cc56608f9/14007/lidar.jpg\" srcset=\"/static/b5ca186f76e25e7467db1c9cc56608f9/ff44c/lidar.jpg 158w,\n/static/b5ca186f76e25e7467db1c9cc56608f9/a6688/lidar.jpg 315w,\n/static/b5ca186f76e25e7467db1c9cc56608f9/14007/lidar.jpg 582w\" sizes=\"(max-width: 582px) 100vw, 582px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n<figcaption style=\"text-align:center; font-weight: bold;\">Figure 1. Lidar instantaneous velocity measurement.</figcaption>\n<br>\n<p><b>Steps needed to obtain a fully autonomous projection system</b>:</p>\n<p>Sense: Gather environment information from sensors.</p>\n<p>Perceive: Filter, interpret &#x26; understand sensor data.</p>\n<p>Decide: Safely choose actions.</p>\n<p>Actuate: Initiate actions.</p>\n<p><b>Challenges</b>: The price for autonomous vehicle protection is relatively expensive. The increase of sensor proximity and real-time detection is becoming more challenging with newer innovations and time optimization. Increase in software complexity. Enlightened in-car passenger exposures.</p>\n<h4>Automakers adopting autonomous technology</h4>\n<table style=\"border: 1px solid black; padding: 5px;\">\n<tr>\n<th style=\"border: 1px solid black; padding: 5px;\">Autonomous Technology</th>\n<th style=\"border: 1px solid black;\">Tesla</th>\n<th style=\"border: 1px solid black;\">BMW</th>\n<th style=\"border: 1px solid black;\">Comments/Concerns</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">1. Multiple Camera Integration</th>\n<th style=\"border: 1px solid black;\">Yes</th>\n<th style=\"border: 1px solid black;\">Yes</th>\n<th style=\"border: 1px solid black;\">Both companies imply the use of interpreting multiple cameras being installed on different areas of each vehicle for providing a better visual representation in its surrounding environment.</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">2. Sensor Manipulation</th>\n<th style=\"border: 1px solid black;\">Yes</th>\n<th style=\"border: 1px solid black;\">Yes</th>\n<th style=\"border: 1px solid black;\">BMW agrees that it will use it's sensors to better help determine a precise location for surrounding vehicles in order to determine if it is acceptable to changes lanes during its operation.</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">3. Ultrasonic sensors and Lidar</th>\n<th style=\"border: 1px solid black;\">No</th>\n<th style=\"border: 1px solid black;\">Yes</th>\n<th style=\"border: 1px solid black;\">Tesla's CEO Elon Musk has said that the adoption of Lidar technologies is fairly expensive and the technology is difficult to mass-produce for consumer vehicles.</th>\n</tr>\n</table>\n<h4>Future</h4>\n<p>Automakers are expected to further integrate multiple AI technologies and neural networks into their systems with the adaptation of computer vision along with software and hardware enhancements such as deep learning algorithms, image recognition and convolutional neural networks.</p>\n<h4>Autonomous Vehicle Job Market Share 2019</h4>\n<table style=\"border: 1px solid black;\">\n<tr>\n<th style=\"border: 1px solid black;\">Rank</th>\n<th style=\"border: 1px solid black;\">Company</th>\n<th style=\"border: 1px solid black;\">Job Openings(%)</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">1</th>\n<th style=\"border: 1px solid black;\">Aptiv</th>\n<th style=\"border: 1px solid black;\">21.7</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">2</th>\n<th style=\"border: 1px solid black;\">Nvidia</th>\n<th style=\"border: 1px solid black;\">5.0</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">3</th>\n<th style=\"border: 1px solid black;\">SAIC Innovation Center</th>\n<th style=\"border: 1px solid black;\">4.8</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">4</th>\n<th style=\"border: 1px solid black;\">Bosch</th>\n<th style=\"border: 1px solid black;\">4.3</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">5</th>\n<th style=\"border: 1px solid black;\">Daimler AG</th>\n<th style=\"border: 1px solid black;\">3.4</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">6</th>\n<th style=\"border: 1px solid black;\">Cruise Automation</th>\n<th style=\"border: 1px solid black;\">3.3</th>\n</tr>\n<tr>\n<th style=\"border: 1px solid black;\">7</th>\n<th style=\"border: 1px solid black;\">General Motors</th>\n<th style=\"border: 1px solid black;\">2.5</th>\n</tr>\n</table>\n<h4>Conclusion</h4>\n<p>It is expected that by the end of 2020, automaker manufacturers will deploy multiple vehicles with integrated semi-fully autonomous features. And by the year 2035, it is expected that most cars will be able to gain full autonomy.</p>","frontmatter":{"title":"Autonomous Vehicles","date":"February 10, 2021","description":"Autonomous Vehicles are certain types of vehicles that are capable of performing similar actions compared to humans in operating driverless technology through the ability to sense it's nearby surroundings."}},"previous":{"fields":{"slug":"/segmentation/"},"frontmatter":{"title":"Segmentation"}},"next":{"fields":{"slug":"/smartwatch/"},"frontmatter":{"title":"Smartwatch Technology"}}},"pageContext":{"id":"419935fe-cf16-549d-b7eb-7f46b4087cf3","previousPostId":"2fe42ba9-c1cb-5b61-b7bc-3c8cb76a550e","nextPostId":"6b993cb9-b9ce-575e-845a-28ea79e2c437"}},"staticQueryHashes":["2841359383","3257411868"]}